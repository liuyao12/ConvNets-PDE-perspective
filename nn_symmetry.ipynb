{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71b6152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, timm, importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e7ed219",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = timm.create_model('resnet50', num_classes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f703be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('output/train/20230914-091722-resnet50-224/model_best.pth.tar')['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "435e2358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f14d984a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): ConvBN(\n",
       "        (conv): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): ConvBN(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip): Identity()\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): ConvBN(\n",
       "        (conv): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): ConvBN(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip): Identity()\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): ConvBN(\n",
       "        (conv): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): ConvBN(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip): Identity()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): ConvBN(\n",
       "        (conv): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): ConvBN(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip): ConvBN(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (act3): hardball()\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): ConvBN(\n",
       "        (conv): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): ConvBN(\n",
       "        (conv): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip): Identity()\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): ConvBN(\n",
       "        (conv): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): ConvBN(\n",
       "        (conv): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip): Identity()\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): ConvBN(\n",
       "        (conv): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): ConvBN(\n",
       "        (conv): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip): Identity()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): ConvBN(\n",
       "        (conv): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): ConvBN(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip): ConvBN(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (act3): hardball()\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): ConvBN(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): ConvBN(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip): Identity()\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): ConvBN(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): ConvBN(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip): Identity()\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): ConvBN(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): ConvBN(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip): Identity()\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): ConvBN(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): ConvBN(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip): Identity()\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): ConvBN(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): ConvBN(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip): Identity()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): ConvBN(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): ConvBN(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip): ConvBN(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (act3): hardball()\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): ConvBN(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
       "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): ConvBN(\n",
       "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip): Identity()\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): ConvBN(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
       "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): ConvBN(\n",
       "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (skip): Identity()\n",
       "    )\n",
       "  )\n",
       "  (act): hardball()\n",
       "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "  (fc): Linear(in_features=512, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2099b937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer >>\n",
      "torch.Size([512, 64, 1, 1])\n",
      "torch.Size([64, 512, 1, 1])\n",
      "torch.Size([512, 64, 1, 1])\n",
      "torch.Size([64, 512, 1, 1])\n",
      "torch.Size([512, 64, 1, 1])\n",
      "torch.Size([64, 512, 1, 1])\n",
      "layer >>\n",
      "torch.Size([512, 64, 1, 1])\n",
      "torch.Size([128, 512, 1, 1])\n",
      "torch.Size([128, 64, 1, 1])\n",
      "torch.Size([1024, 128, 1, 1])\n",
      "torch.Size([128, 1024, 1, 1])\n",
      "torch.Size([1024, 128, 1, 1])\n",
      "torch.Size([128, 1024, 1, 1])\n",
      "torch.Size([1024, 128, 1, 1])\n",
      "torch.Size([128, 1024, 1, 1])\n",
      "layer >>\n",
      "torch.Size([1024, 128, 1, 1])\n",
      "torch.Size([256, 1024, 1, 1])\n",
      "torch.Size([256, 128, 1, 1])\n",
      "torch.Size([1024, 256, 1, 1])\n",
      "torch.Size([256, 1024, 1, 1])\n",
      "torch.Size([1024, 256, 1, 1])\n",
      "torch.Size([256, 1024, 1, 1])\n",
      "torch.Size([1024, 256, 1, 1])\n",
      "torch.Size([256, 1024, 1, 1])\n",
      "torch.Size([1024, 256, 1, 1])\n",
      "torch.Size([256, 1024, 1, 1])\n",
      "torch.Size([1024, 256, 1, 1])\n",
      "torch.Size([256, 1024, 1, 1])\n",
      "layer >>\n",
      "torch.Size([1024, 256, 1, 1])\n",
      "torch.Size([512, 1024, 1, 1])\n",
      "torch.Size([512, 256, 1, 1])\n",
      "torch.Size([2048, 512, 1, 1])\n",
      "torch.Size([512, 2048, 1, 1])\n",
      "torch.Size([2048, 512, 1, 1])\n",
      "torch.Size([512, 2048, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# fuse ConvBN\n",
    "for layer in [m.layer1, m.layer2, m.layer3, m.layer4]:\n",
    "    print(\"layer >>\")\n",
    "    for block in layer:\n",
    "        # Fuse the weights in conv1 and conv3\n",
    "        block.conv1.fuse_bn()\n",
    "        print(block.conv1.fused_weight.size())\n",
    "        block.conv3.fuse_bn()\n",
    "        print(block.conv3.fused_weight.size())\n",
    "        if block.act3 is not None:\n",
    "            layer[0].skip.fuse_bn()\n",
    "            print(layer[0].skip.fused_weight.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dccbf19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def validate(model, data_dir, batch_size=32):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    device = 'cpu'\n",
    "    # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # Define the transform\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Load the data\n",
    "    val_dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    # Initialize metrics\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss = 0\n",
    "\n",
    "    # Define the loss function\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            # Move data to the appropriate device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss += criterion(outputs, labels).item()\n",
    "\n",
    "            # Get the predicted class\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            # Update metrics\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Calculate final metrics\n",
    "    accuracy = 100 * correct / total\n",
    "    avg_loss = loss / len(val_loader)\n",
    "\n",
    "    print(f'Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0c74a04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6637, Accuracy: 85.02%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6637252083982143, 85.02)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(m, '../datasets/imagenet100/val/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3a55f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt = torch.randn(1,3,224,224)\n",
    "out_old = m(inpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5991c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transform(block1, block2, Q, keep_identity=True):\n",
    "    with torch.no_grad():\n",
    "        # Ensure that the out_channels of block1 is equal to the in_channels of block2\n",
    "        assert Q.size()[0] == Q.size()[1], \"Q needs to be a square matrix\"\n",
    "        n = Q.size()[0]\n",
    "        assert block1.conv3.conv.out_channels == n and block2.conv1.conv.in_channels == n, \"Mismatched channels between blocks\"\n",
    "\n",
    "        # Generate a random orthogonal matrix Q of order n\n",
    "        n = block1.conv3.conv.out_channels\n",
    "        \n",
    "        # Calculate the inverse of Q\n",
    "        Q_inv = torch.inverse(Q)\n",
    "\n",
    "        # Modify the weights of conv layers in block1\n",
    "        block1.conv3.fused_weight.data = torch.einsum('ij,jklm->iklm', Q, block1.conv3.fused_weight.data)\n",
    "        block1.conv3.fused_bias.data = torch.einsum('ij,j->i', Q, block1.conv3.fused_bias.data)\n",
    "        \n",
    "        if keep_identity and isinstance(block1.skip, torch.nn.Identity):\n",
    "            block1.skip = torch.nn.Conv2d(n, n, kernel_size=1, bias=False)\n",
    "            block1.skip.weight.data = Q.unsqueeze(-1).unsqueeze(-1)\n",
    "        if block1.act3 is not None:\n",
    "            block1.skip.fused_weight.data = torch.einsum('ij,jklm->iklm', Q, block1.skip.fused_weight.data)\n",
    "            block1.skip.fused_bias.data = torch.einsum('ij,j->i', Q, block1.skip.fused_bias.data)\n",
    "\n",
    "        # Modify the weights of conv layers in block2\n",
    "        block2.conv1.fused_weight.data = torch.einsum('ki,jklm->jilm', Q_inv, block2.conv1.fused_weight.data)\n",
    "        \n",
    "        if keep_identity and isinstance(block2.skip, torch.nn.Identity):\n",
    "            block2.skip = torch.nn.Conv2d(n, n, kernel_size=1, bias=False)\n",
    "            block2.skip.weight.data = Q_inv.unsqueeze(-1).unsqueeze(-1)\n",
    "        if block2.act3 is not None:\n",
    "            block2.skip.fused_weight.data = torch.einsum('ki,jklm->jilm', Q_inv, block2.skip.fused_weight.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd96acd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = torch.nn.init.orthogonal_(torch.empty(256, 256))\n",
    "for i in range(5):\n",
    "    apply_transform(m.layer3[i], m.layer3[i+1], Q, False)\n",
    "apply_transform(m.layer3[5], m.layer4[0], Q, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fce3a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6637, Accuracy: 85.02%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.66372525997428, 85.02)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(m, '../datasets/imagenet100/val/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5d3628d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.537799835205078e-05\n"
     ]
    }
   ],
   "source": [
    "out_new = m(inpt)\n",
    "print((out_new - out_old).abs().max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a54fe8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
